
import unicodedata

import pandas as pd
from fuzzywuzzy import fuzz, process
from statsmodels.stats.outliers_influence import variance_inflation_factor


def clean_text(text):
    """Chu·∫©n h√≥a chu·ªói: ch·ªØ th∆∞·ªùng, lo·∫°i b·ªè d·∫•u, k√Ω t·ª± ƒë·∫∑c bi·ªát v√† kho·∫£ng tr·∫Øng d∆∞ th·ª´a."""
    if not isinstance(text, str):
        return ''
    text = text.lower().strip()
    text = ''.join(c for c in unicodedata.normalize('NFKD', text) if unicodedata.category(c) != 'Mn')
    text = text.replace('-', ' ').replace('_', ' ').replace('.', '')
    return text



# ======== üîç 2. H√†m so kh·ªõp (Fuzzy Matching) ========
def fuzzy_match(query, choices, scorer=fuzz.token_set_ratio, cutoff=80, top_n=1):
    """So kh·ªõp fuzzy cho m·ªôt chu·ªói query v·ªõi danh s√°ch l·ª±a ch·ªçn."""
    matches = process.extract(query, choices, scorer=scorer, limit=top_n)
    return [(match, score) for match, score in matches if score >= cutoff]

# ======== üéõÔ∏è 3. Multi-pass Matching (So kh·ªõp nhi·ªÅu b∆∞·ªõc) ========
def multi_pass_match(query, choices):
    for cutoff in [90, 80, 70]:
        matches = fuzzy_match(query, choices, cutoff=cutoff, top_n=10)
        if matches:
            return matches[0]  # Tr·∫£ v·ªÅ k·∫øt qu·∫£ t·ªët nh·∫•t
    return None, 0

# ======== üéöÔ∏è 4. √Ånh x·∫° s·∫£n ph·∫©m th√¥ng minh ========
def map_products(
    source_df, source_col, target_df, target_col,
    groupby=None, scorer=fuzz.token_set_ratio, cutoff=80, top_n=1
):
    """
    √Ånh x·∫° s·∫£n ph·∫©m th√¥ng minh gi·ªØa hai DataFrame.
    - H·ªó tr·ª£ groupby theo danh m·ª•c (n·∫øu c√≥).
    - √Ånh x·∫° qua nhi·ªÅu b∆∞·ªõc v√† t√≠nh ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng.
    """
    results = []

    # H√†m √°nh x·∫° trong t·ª´ng nh√≥m danh m·ª•c
    def process_group(source_group, target_group):
        source_products = source_group[source_col].dropna().unique()
        target_products = target_group[target_col].dropna().unique()

        for source_product in source_products:
            clean_source = clean_text(source_product)
            best_match, score = multi_pass_match(clean_source, [clean_text(t) for t in target_products])

            if best_match:
                results.append({
                    'Category': source_group[groupby].iloc[0] if groupby else 'N/A',
                    source_col: source_product,
                    target_col: best_match,
                    'Score': score,
                    'Similarity %': f"{score}%"
                })

    # N·∫øu c√≥ groupby, groupby ƒë·ªÉ x·ª≠ l√Ω t·ª´ng danh m·ª•c
    if groupby and groupby in source_df.columns and groupby in target_df.columns:
        for category, source_group in source_df.groupby(groupby):
            target_group = target_df[target_df[groupby] == category]
            process_group(source_group, target_group)
    else:
        # N·∫øu kh√¥ng c√≥ danh m·ª•c, so kh·ªõp to√†n b·ªô
        process_group(source_df, target_df)

    return pd.DataFrame(results)

def VIF(model):
    # Assuming X is the design matrix used to fit the model
    X = model.model.exog

    # Create a DataFrame to store VIF values
    vif_data = pd.DataFrame()
    vif_data['feature'] = model.model.exog_names

    # Calculate VIF for each feature
    vif_data['VIF'] = [variance_inflation_factor(X, i) for i in range(X.shape[1])]

    vif_data['R-squared'] = model.rsquared
    return vif_data